# Intro
Привет! Меня зовут Станислав Попов, и это моё портфолио. 

Сюда я буду регулярно выкладывать проекты с целью продемонстрировать свои навыки.

Ниже я написал о проектах, на которые хочу обратить внимание.

## Классификация жалоб пользователей

Ссылка на Google Colab: https://colab.research.google.com/drive/1lohUCc9GjeMuXZEqz1VYm2oqTPgBA3G2?usp=sharing.

Ссылка на Github: [Классификация_жалоб_пользователей.ipynb](https://github.com/Popov-SS/Portfolio/blob/master/Complaint%20ticket%20classification/%D0%9A%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D1%8F_%D0%B6%D0%B0%D0%BB%D0%BE%D0%B1_%D0%BF%D0%BE%D0%BB%D1%8C%D0%B7%D0%BE%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D0%B5%D0%B9.ipynb)

Цель работы - проанализировать жалобные обращения в службу поддержки клиентов, выделить их темы, обучить модель для классификации тем.

Заказчик - финтех компания. Данные предствалены в формате JSON, и содержат информацию об обращениях пользователей в службу поддержки клиентов. Некоторые из них содержат текст обращения, который предстоит анализировать. Разметка тем обращений отсутствует.

**Что я сделал**:
* Настроил среду для работы, скачал файл, выбрал необходимые данные;
* Настроил пайплайн обработки текста (удаление лишних символов, токенизация, лемматизация);
* Провел разведовательный анализ по распределению длин обработанных обращений, а также самым частым словам и словосочетаниям;
* Обучил 2 модели для моделирования тем (LDA, NMF) и сравнил их результаты;
* Обучил 4 модели классификации темы обращения (Logistic Regression, SVC, CatBoostClassifier, ComplementNB) и сравнил результаты их работы;

Темы обращений были сформированы заранее, так что искать оптимальное число тем не пришлось. Полученные темы были достаточно согласованными. Более стабильный и быстрый результат получила модель NMF, поэтому для классификации я использовал темы, полученные от неё.

Среди классификационных моделей, лучший результат показала Logistic Regression. У неё были самые высокие показатели precision, recall и f-score. На втором месте - SVM. Обучалась немного дольше, показатели немного ниже. На третьем месте - CatBoostClassifier, который обучался значительно дольше других моделей, но не показал значительного увеличения показателей. Хуже всех справился ComplementNB.

## Дейплой модели классификации жалоб

Ссылка на Github: [Complaint classification (deployment)](https://github.com/Popov-SS/Portfolio/tree/master/Complaint%20classification%20(deployment)). Более подробное описание в README-файле в директории.

Для этого проекта я взял модель из прошлого проекта и сделал из неё микросервис. Для этого я написал простое приложение на Flask и запустил его внутри Docker-контейнера. Контейнер был запущен на Linux Ubuntu 22.04.3 внутри виртуальной машины.

**Что я сделал**:
* Написал простое приложение на Flask;
* Написал Dockerfile и создал образ контейнера;
* Проверил работу контейнера;

## A/B-тест программы лояльности

Ссылка на Google Colab: https://colab.research.google.com/drive/1fnH3KnctXhMkyhrMLT8b7-CqdBSFX_f9?usp=sharing

Ссылка на Github: [A_B_тест_программы_лояльности.ipynb](https://github.com/Popov-SS/Portfolio/blob/master/Loyalty%20program%20AB-test/A_B_%D1%82%D0%B5%D1%81%D1%82_%D0%BF%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D1%8B_%D0%BB%D0%BE%D1%8F%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D0%B8.ipynb)

Цель работы - проанализировать результаты A/B-теста, оценить эффективность нововведений.

Заказчик - крупная сеть продуктовых магазинов. Одна из целей, которую ставит перед собой компания - привлечь больше покупателей к скачиванию мобильного приложения и регистрации в программе лояльности. Для этого на сайте магазина изменили дизайн кнопки для скачивания приложения и провели A/B-тест для оценки эффективности нововведения.

Подробности эксперимента:
* Единицей диверсификации в данном эксперименте является IP-адрес;
* Целевая аудитория - посетители сайта без учетной записи;
* Продолжительность теста - 1 неделя;
* Размер тестовых и контрольных групп - 1/3 и 2/3 всех испытуемых;

**Что я сделал**:
* Скачал файл, подготовил данные к проведению теста;
* Рассчитал значения тестов Шапиро-Уилка, Левена и Манна-Уитни с целью доказать статистическую значимость между показателями целевого значения в разных группах;
* Сделал вывод об эффективности нововведения на основе значений тестов;

Тест Шапиро-Уилка показал, что целевое значение не имеет нормального распределения в обеих группах. Тест Левена показал, что дисперсии выборок не являются однородными. Тест Манна-Уитни показал, что контрольные и тестовые выборки имеют разные распределения, поэтому разница в значении целевого значений в группах имеет статистическую значимость.

Среди пользователей из контрольной группы, 18.6% перешли по ссылке для скачивания приложения. Среди пользователей из тестовой группы, 23.3% перешли по ссылке для скачивания приложения. По результатам теста можно сказать, что эта разница имеет статистическую значимость. Изменение дизайна кнопки для скачивания приложения действительно увеличило число переходов на страницу скачивания на 4.7 п.п. (25%).
